{
  "source": "quant_finance_risk_management",
  "created_at": "2025-11-09",
  "total_pairs": 1,
  "description": "Risk Management Q&A - Value at Risk (VaR) for cryptocurrency portfolios",
  "qa_pairs": [
    {
      "pair_id": "quant_risk_001",
      "topic": "Value at Risk VaR cryptocurrency portfolio risk measurement tail risk",
      "question": "How is Value at Risk (VaR) calculated and applied to cryptocurrency portfolios, and what are the specific challenges and adaptations needed for crypto markets?",
      "answer": "Value at Risk (VaR) is a statistical measure that quantifies the maximum potential loss a portfolio could experience over a specified time period at a given confidence level. Originally developed by J.P. Morgan in the 1990s (RiskMetrics), VaR has become the industry standard for risk measurement in financial institutions. For cryptocurrency portfolios, VaR must be adapted to handle extreme volatility, fat-tailed distributions, and 24/7 trading. Here's the comprehensive guide:\n\n**Value at Risk Theory:**\n\n**Formal Definition:**\nVaR_Î± = inf{l : P(L > l) â‰¤ 1 - Î±}\n\nWhere:\n- VaR_Î± = Value at Risk at confidence level Î±\n- L = Portfolio loss\n- Î± = Confidence level (typically 95% or 99%)\n- 1 - Î± = Probability of loss exceeding VaR\n\n**Interpretation:**\n\"With Î±% confidence, losses will not exceed VaR over the next T days.\"\n\nExample: Daily 95% VaR = $10,000\n- Meaning: 95% confidence that daily loss â‰¤ $10,000\n- Or: 5% chance of losing more than $10,000 in one day\n- Expected: ~1 VaR breach per 20 trading days\n\n**Three Methods to Calculate VaR:**\n\n**1. Historical Simulation (Non-parametric)**\n\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\ndef historical_var(returns, confidence_level=0.95):\n    \"\"\"\n    Calculate VaR using historical simulation\n    \n    Args:\n        returns: Array or Series of historical returns\n        confidence_level: Confidence level (e.g., 0.95 = 95%)\n    \n    Returns:\n        VaR as a positive number (loss)\n    \"\"\"\n    # Sort returns from worst to best\n    sorted_returns = np.sort(returns)\n    \n    # Find the percentile corresponding to (1 - confidence_level)\n    var_percentile = 1 - confidence_level\n    var_index = int(var_percentile * len(sorted_returns))\n    \n    # VaR is the loss at that percentile (make positive)\n    var = -sorted_returns[var_index]\n    \n    return var\n\n# Example: BTC portfolio\nnp.random.seed(42)\nbtc_returns = np.random.normal(0.001, 0.04, 365)  # Daily returns (simulated)\n\nvar_95 = historical_var(btc_returns, confidence_level=0.95)\nvar_99 = historical_var(btc_returns, confidence_level=0.99)\n\nprint(\"ðŸ“Š HISTORICAL VAR\")\nprint(\"=\" * 70)\nprint(f\"95% Daily VaR: {var_95*100:.2f}% (95% confident loss â‰¤ this)\")\nprint(f\"99% Daily VaR: {var_99*100:.2f}% (99% confident loss â‰¤ this)\")\n\n# Dollar VaR for $100,000 portfolio\nportfolio_value = 100000\nprint(f\"\\nFor ${portfolio_value:,} portfolio:\")\nprint(f\"95% Daily VaR: ${var_95 * portfolio_value:,.2f}\")\nprint(f\"99% Daily VaR: ${var_99 * portfolio_value:,.2f}\")\n```\n\n**2. Variance-Covariance (Parametric - Normal Distribution)**\n\n```python\ndef parametric_var(returns, confidence_level=0.95):\n    \"\"\"\n    Calculate VaR assuming normal distribution\n    \n    Pros: Fast, smooth\n    Cons: Underestimates tail risk (crypto has fat tails)\n    \"\"\"\n    # Mean and std of returns\n    mu = np.mean(returns)\n    sigma = np.std(returns)\n    \n    # Z-score for confidence level\n    z_score = stats.norm.ppf(1 - confidence_level)\n    \n    # VaR = -(Î¼ + z*Ïƒ)\n    # For 95%: z â‰ˆ -1.645\n    # For 99%: z â‰ˆ -2.326\n    var = -(mu + z_score * sigma)\n    \n    return var\n\nvar_95_param = parametric_var(btc_returns, 0.95)\nvar_99_param = parametric_var(btc_returns, 0.99)\n\nprint(\"\\nðŸ“ PARAMETRIC VAR (Normal Assumption)\")\nprint(\"=\" * 70)\nprint(f\"95% Daily VaR: {var_95_param*100:.2f}%\")\nprint(f\"99% Daily VaR: {var_99_param*100:.2f}%\")\n\n# Compare with historical\nprint(f\"\\nHistorical vs. Parametric:\")\nprint(f\"95% VaR: {var_95*100:.2f}% (hist) vs {var_95_param*100:.2f}% (param)\")\nprint(f\"99% VaR: {var_99*100:.2f}% (hist) vs {var_99_param*100:.2f}% (param)\")\n```\n\n**3. Monte Carlo Simulation**\n\n```python\ndef monte_carlo_var(returns, confidence_level=0.95, n_simulations=10000, horizon=1):\n    \"\"\"\n    Calculate VaR using Monte Carlo simulation\n    \n    Args:\n        returns: Historical returns\n        confidence_level: Confidence level\n        n_simulations: Number of scenarios to simulate\n        horizon: Time horizon (days)\n    \n    Returns:\n        VaR estimate\n    \"\"\"\n    # Estimate parameters from historical data\n    mu = np.mean(returns)\n    sigma = np.std(returns)\n    \n    # Simulate returns\n    simulated_returns = np.random.normal(\n        mu * horizon,\n        sigma * np.sqrt(horizon),\n        n_simulations\n    )\n    \n    # Calculate VaR from simulated distribution\n    var = historical_var(simulated_returns, confidence_level)\n    \n    return var\n\nvar_95_mc = monte_carlo_var(btc_returns, 0.95, n_simulations=10000)\nvar_99_mc = monte_carlo_var(btc_returns, 0.99, n_simulations=10000)\n\nprint(\"\\nðŸŽ² MONTE CARLO VAR\")\nprint(\"=\" * 70)\nprint(f\"95% Daily VaR: {var_95_mc*100:.2f}%\")\nprint(f\"99% Daily VaR: {var_99_mc*100:.2f}%\")\n```\n\n**Multi-Asset Portfolio VaR:**\n\n```python\ndef portfolio_var(returns_df, weights, confidence_level=0.95):\n    \"\"\"\n    Calculate VaR for multi-asset portfolio\n    \n    Args:\n        returns_df: DataFrame with returns for each asset (columns)\n        weights: Portfolio weights (numpy array)\n        confidence_level: Confidence level\n    \n    Returns:\n        Portfolio VaR\n    \"\"\"\n    # Calculate portfolio returns\n    portfolio_returns = (returns_df * weights).sum(axis=1)\n    \n    # Calculate VaR\n    var = historical_var(portfolio_returns.values, confidence_level)\n    \n    return var\n\n# Example: 5-asset crypto portfolio\nnp.random.seed(42)\nassets = ['BTC', 'ETH', 'BNB', 'ADA', 'SOL']\nreturns_df = pd.DataFrame({\n    'BTC': np.random.normal(0.0008, 0.03, 252),\n    'ETH': np.random.normal(0.0010, 0.04, 252),\n    'BNB': np.random.normal(0.0012, 0.05, 252),\n    'ADA': np.random.normal(0.0015, 0.06, 252),\n    'SOL': np.random.normal(0.0018, 0.07, 252)\n})\n\nweights = np.array([0.35, 0.25, 0.20, 0.12, 0.08])\n\nport_var_95 = portfolio_var(returns_df, weights, 0.95)\nport_var_99 = portfolio_var(returns_df, weights, 0.99)\n\nprint(\"\\nðŸ’¼ PORTFOLIO VAR\")\nprint(\"=\" * 70)\nprint(\"Weights:\", {asset: f\"{w*100:.1f}%\" for asset, w in zip(assets, weights)})\nprint(f\"\\n95% Daily VaR: {port_var_95*100:.2f}%\")\nprint(f\"99% Daily VaR: {port_var_99*100:.2f}%\")\n```\n\n**Crypto-Specific VaR Adaptations:**\n\n**1. Fat-Tailed Distributions (Student's t-distribution)**\n\nCrypto returns have fat tails (more extreme events than normal distribution):\n\n```python\ndef fat_tailed_var(returns, confidence_level=0.95):\n    \"\"\"\n    Calculate VaR using Student's t-distribution\n    Better for crypto's heavy tails\n    \"\"\"\n    # Fit t-distribution to returns\n    params = stats.t.fit(returns)\n    df, loc, scale = params  # degrees of freedom, location, scale\n    \n    # Calculate VaR using t-distribution\n    var_percentile = 1 - confidence_level\n    var = -stats.t.ppf(var_percentile, df, loc, scale)\n    \n    return var, df\n\nvar_95_t, df = fat_tailed_var(btc_returns, 0.95)\nvar_99_t, _ = fat_tailed_var(btc_returns, 0.99)\n\nprint(\"\\nðŸ“‰ FAT-TAILED VAR (Student's t)\")\nprint(\"=\" * 70)\nprint(f\"Degrees of freedom: {df:.2f} (lower = fatter tails)\")\nprint(f\"95% VaR: {var_95_t*100:.2f}% (t-dist) vs {var_95_param*100:.2f}% (normal)\")\nprint(f\"99% VaR: {var_99_t*100:.2f}% (t-dist) vs {var_99_param*100:.2f}% (normal)\")\nprint(f\"\\nDifference at 99%: {(var_99_t - var_99_param)*100:.2f}% (t-dist captures more tail risk)\")\n```\n\n**2. GARCH-based VaR (Time-Varying Volatility)**\n\nCrypto volatility clusters (high vol follows high vol):\n\n```python\nfrom arch import arch_model\n\ndef garch_var(returns, confidence_level=0.95, horizon=1):\n    \"\"\"\n    Calculate VaR using GARCH model for volatility\n    Captures volatility clustering in crypto\n    \"\"\"\n    # Fit GARCH(1,1) model\n    model = arch_model(returns * 100, vol='Garch', p=1, q=1)  # Scale for numerical stability\n    fitted = model.fit(disp='off')\n    \n    # Forecast volatility\n    forecast = fitted.forecast(horizon=horizon)\n    predicted_vol = np.sqrt(forecast.variance.values[-1, :] / 100)  # Rescale\n    \n    # VaR = -z * Ïƒ_forecast (assuming zero mean for short horizon)\n    z_score = stats.norm.ppf(1 - confidence_level)\n    var = -z_score * predicted_vol[0]\n    \n    return var\n\n# Example (simplified - would use on longer history)\nvar_95_garch = garch_var(btc_returns, 0.95)\nprint(f\"\\nâ±ï¸  GARCH VAR (Time-Varying Volatility)\")\nprint(f\"95% 1-day VaR: {var_95_garch*100:.2f}%\")\n```\n\n**3. Extreme Value Theory (EVT)**\n\nFocus on tail behavior only:\n\n```python\nfrom scipy.stats import genpareto\n\ndef evt_var(returns, confidence_level=0.99, threshold_percentile=0.90):\n    \"\"\"\n    Calculate VaR using Extreme Value Theory\n    Best for estimating very high confidence levels (99%, 99.9%)\n    \"\"\"\n    # Extract tail observations (losses beyond threshold)\n    threshold = np.percentile(returns, threshold_percentile * 100)\n    exceedances = returns[returns > threshold] - threshold\n    \n    # Fit Generalized Pareto Distribution to exceedances\n    params = genpareto.fit(exceedances)\n    \n    # Calculate VaR from GPD\n    var_percentile = (confidence_level - threshold_percentile) / (1 - threshold_percentile)\n    var_excess = genpareto.ppf(var_percentile, *params)\n    var = -(threshold + var_excess)\n    \n    return var\n\n# For extreme tails (99.9% VaR)\nvar_999 = evt_var(btc_returns, confidence_level=0.999, threshold_percentile=0.90)\nprint(f\"\\nðŸ”¥ EXTREME VALUE THEORY VAR\")\nprint(f\"99.9% VaR: {var_999*100:.2f}% (1-in-1000 day loss)\")\n```\n\n**4. Time-Scaled VaR (Multi-day Horizons)**\n\n```python\ndef time_scaled_var(daily_var, horizon_days):\n    \"\"\"\n    Scale VaR to different time horizons\n    \n    Square-root-of-time rule: VaR_T = VaR_1 Ã— âˆšT\n    \n    WARNING: Assumes:\n    - Returns are i.i.d. (independent, identically distributed)\n    - No autocorrelation\n    - Crypto often violates these assumptions!\n    \"\"\"\n    return daily_var * np.sqrt(horizon_days)\n\n# Example: Scale daily VaR to weekly, monthly\nvar_1d = var_95\nvar_1w = time_scaled_var(var_1d, 7)\nvar_1m = time_scaled_var(var_1d, 30)\n\nprint(\"\\nðŸ“… TIME-SCALED VAR (95%)\")\nprint(\"=\" * 70)\nprint(f\"1-day VaR:  {var_1d*100:.2f}%\")\nprint(f\"1-week VaR: {var_1w*100:.2f}% (âˆš7 scaling)\")\nprint(f\"1-month VaR: {var_1m*100:.2f}% (âˆš30 scaling)\")\n\nfor $100,000 portfolio:\nprint(f\"\\nFor $100,000 portfolio:\")\nprint(f\"1-day:  ${var_1d * 100000:,.0f}\")\nprint(f\"1-week: ${var_1w * 100000:,.0f}\")\nprint(f\"1-month: ${var_1m * 100000:,.0f}\")\n```\n\n**VaR Backtesting:**\n\n```python\ndef var_backtest(returns, confidence_level=0.95, window=252):\n    \"\"\"\n    Backtest VaR model performance\n    \n    Good model: violations â‰ˆ (1 - confidence_level) Ã— n_days\n    \"\"\"\n    violations = []\n    var_estimates = []\n    \n    for i in range(window, len(returns)):\n        # Calculate VaR using rolling window\n        historical_window = returns[i-window:i]\n        var = historical_var(historical_window, confidence_level)\n        var_estimates.append(var)\n        \n        # Check if actual loss exceeds VaR\n        actual_loss = -returns[i]  # Make loss positive\n        if actual_loss > var:\n            violations.append(1)\n        else:\n            violations.append(0)\n    \n    # Statistics\n    n_days = len(violations)\n    n_violations = sum(violations)\n    expected_violations = n_days * (1 - confidence_level)\n    violation_rate = n_violations / n_days\n    \n    return {\n        'n_days': n_days,\n        'n_violations': n_violations,\n        'expected_violations': expected_violations,\n        'violation_rate': violation_rate,\n        'expected_rate': 1 - confidence_level\n    }\n\n# Backtest\nbacktest_results = var_backtest(btc_returns, confidence_level=0.95, window=100)\n\nprint(\"\\nðŸ§ª VAR BACKTESTING (95% confidence)\")\nprint(\"=\" * 70)\nprint(f\"Test period: {backtest_results['n_days']} days\")\nprint(f\"VaR violations: {backtest_results['n_violations']} (actual)\")\nprint(f\"Expected violations: {backtest_results['expected_violations']:.1f} (5% of days)\")\nprint(f\"Violation rate: {backtest_results['violation_rate']*100:.2f}% (actual)\")\nprint(f\"Expected rate: {backtest_results['expected_rate']*100:.2f}%\")\n\nif abs(backtest_results['violation_rate'] - backtest_results['expected_rate']) < 0.02:\n    print(\"\\nâœ… VaR model is well-calibrated\")\nelse:\n    print(\"\\nâš ï¸  VaR model may need adjustment\")\n```\n\n**Component VaR (Risk Decomposition):**\n\n```python\ndef component_var(returns_df, weights, confidence_level=0.95):\n    \"\"\"\n    Decompose portfolio VaR by asset contribution\n    \"\"\"\n    # Portfolio returns\n    portfolio_returns = (returns_df * weights).sum(axis=1)\n    \n    # Portfolio VaR\n    port_var = historical_var(portfolio_returns.values, confidence_level)\n    \n    # Component VaR (contribution of each asset)\n    component_vars = []\n    for i, asset in enumerate(returns_df.columns):\n        # Marginal VaR: âˆ‚VaR/âˆ‚w_i\n        # Approximate by finite difference\n        delta_w = 0.01\n        weights_plus = weights.copy()\n        weights_plus[i] += delta_w\n        weights_plus = weights_plus / weights_plus.sum()  # Renormalize\n        \n        portfolio_returns_plus = (returns_df * weights_plus).sum(axis=1)\n        var_plus = historical_var(portfolio_returns_plus.values, confidence_level)\n        \n        marginal_var = (var_plus - port_var) / delta_w\n        component_var_i = weights[i] * marginal_var\n        component_vars.append(component_var_i)\n    \n    return np.array(component_vars), port_var\n\ncomp_vars, total_var = component_var(returns_df, weights, 0.95)\n\nprint(\"\\nðŸ” COMPONENT VAR ANALYSIS\")\nprint(\"=\" * 70)\nprint(f\"Portfolio 95% VaR: {total_var*100:.2f}%\\n\")\nprint(f\"{'Asset':<8} {'Weight':<12} {'Component VaR':<18} {'% of Total'}\")\nprint(\"-\" * 70)\nfor asset, w, cv in zip(assets, weights, comp_vars):\n    pct_contribution = (cv / total_var) * 100 if total_var != 0 else 0\n    print(f\"{asset:<8} {w*100:>6.1f}%      {cv*100:>8.3f}%          {pct_contribution:>8.1f}%\")\n```\n\n**Practical VaR Guidelines for Crypto:**\n\n**Method Selection:**\n\n| Method | Best For | Crypto Suitability |\n|--------|----------|--------------------|\n| Historical | Simple, transparent | â­â­â­ Good |\n| Parametric (Normal) | Fast calculation | â­ Poor (underestimates tails) |\n| Monte Carlo | Flexibility | â­â­â­ Good |\n| GARCH | Volatility clustering | â­â­â­â­ Excellent |\n| Student's t | Fat tails | â­â­â­â­ Excellent |\n| EVT | Extreme tails (99%+) | â­â­â­â­ Excellent for 99%+ |\n\n**Confidence Levels:**\n- 95% VaR: Standard for daily risk management\n- 99% VaR: Regulatory (Basel III uses this)\n- 99.9% VaR: Stress testing\n\n**Time Horizons:**\n- 1-day: Active trading, daily limits\n- 1-week: Short-term risk budgeting\n- 1-month: Medium-term capital allocation\n\n**Limitations of VaR:**\n\n1. **Doesn't measure tail losses** - Only threshold, not severity beyond\n2. **Not subadditive** - Portfolio VaR can > sum of individual VaRs\n3. **Model risk** - Wrong assumptions = wrong VaR\n4. **Backward-looking** - Based on history (regime changes not captured)\n5. **Gaming risk** - Can be optimized against (sell vol after losses)\n\n**VaR vs. CVaR (Conditional VaR / Expected Shortfall):**\n\nCVaR measures the expected loss GIVEN that VaR is exceeded:\n\nCVaR_Î± = E[L | L > VaR_Î±]\n\nCVaR is preferred because:\n- Subadditive (portfolio CVaR â‰¤ sum of component CVaRs)\n- Captures tail severity\n- Coherent risk measure\n\n**Key Insights:**\n\n1. **Use multiple methods** - Historical + GARCH + t-distribution\n2. **Backtest religiously** - VaR is only useful if accurate\n3. **Assume fat tails** - Normal distribution fails for crypto\n4. **Short lookback** - 3-6 months max (crypto regime changes)\n5. **Don't rely solely on VaR** - Supplement with stress tests, CVaR\n\n**Academic Sources:**\n- Jorion, P. (2006). \"Value at Risk: The New Benchmark for Managing Financial Risk.\"\n- \"Cryptocurrency Risk Management\" - Journal of Risk (2021)\n- \"VaR for Bitcoin Portfolios\" - Digital Finance (2020)\n- Basel Committee on Banking Supervision - \"Minimum Capital Requirements for Market Risk\" (2019)\n- McNeil, A., Frey, R., Embrechts, P. (2015). \"Quantitative Risk Management.\"",
      "category": "Quantitative Finance",
      "subcategory": "Risk Management",
      "difficulty": "Graduate"
    }
  ]
}
