{
  "source": "quant_finance_portfolio_construction",
  "created_at": "2025-11-09",
  "total_pairs": 1,
  "description": "Portfolio Construction Q&A - Risk Parity for cryptocurrency portfolio allocation",
  "qa_pairs": [
    {
      "pair_id": "quant_portfolio_003",
      "topic": "Risk Parity portfolio cryptocurrency equal risk contribution volatility",
      "question": "How does Risk Parity portfolio construction work for cryptocurrency portfolios, and how does it differ from traditional market-cap weighted or mean-variance approaches?",
      "answer": "Risk Parity is a portfolio allocation methodology that weights assets by their risk contribution rather than by market capitalization or expected returns. The goal is to achieve equal risk contribution from each asset, creating a more balanced and diversified portfolio. Developed and popularized by firms like Bridgewater Associates (Ray Dalio's \"All Weather Portfolio\"), Risk Parity is particularly relevant for cryptocurrency portfolios due to the extreme volatility differences across assets. Here's the comprehensive guide:\n\n**Risk Parity Theory:**\n\n**Core Principle:**\nEach asset contributes equally to total portfolio risk.\n\n**Risk Contribution Formula:**\nRC_i = w_i Ã— (âˆ‚Ïƒ_p / âˆ‚w_i)\n\nWhere:\n- RC_i = Risk contribution of asset i\n- w_i = Weight of asset i\n- Ïƒ_p = Portfolio volatility\n- âˆ‚Ïƒ_p / âˆ‚w_i = Marginal contribution to risk\n\n**Marginal Risk Contribution:**\nMRC_i = (Î£ w_j Ã— Cov(R_i, R_j)) / Ïƒ_p\n\nWhere:\n- Cov(R_i, R_j) = Covariance between assets i and j\n- Ïƒ_p = Portfolio standard deviation\n\n**Risk Parity Condition:**\nRC_1 = RC_2 = ... = RC_n = Ïƒ_p / n\n\nEach asset contributes 1/n of total portfolio risk.\n\n**Inverse Volatility Weighting (Simplified):**\nw_i = (1/Ïƒ_i) / Î£(1/Ïƒ_j)\n\nWhere Ïƒ_i is the volatility of asset i.\n\n**Basic Risk Parity Implementation:**\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom scipy.optimize import minimize\nimport matplotlib.pyplot as plt\n\ndef calculate_portfolio_volatility(weights, cov_matrix):\n    \"\"\"\n    Calculate portfolio volatility\n    \"\"\"\n    return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n\ndef calculate_risk_contribution(weights, cov_matrix):\n    \"\"\"\n    Calculate risk contribution of each asset\n    \n    Returns:\n        Array of risk contributions (sum = portfolio volatility)\n    \"\"\"\n    portfolio_vol = calculate_portfolio_volatility(weights, cov_matrix)\n    \n    # Marginal contribution to risk\n    marginal_contrib = np.dot(cov_matrix, weights) / portfolio_vol\n    \n    # Risk contribution = weight Ã— marginal contribution\n    risk_contrib = weights * marginal_contrib\n    \n    return risk_contrib\n\ndef risk_parity_objective(weights, cov_matrix):\n    \"\"\"\n    Objective function: minimize difference in risk contributions\n    \"\"\"\n    risk_contrib = calculate_risk_contribution(weights, cov_matrix)\n    \n    # Target: equal risk contribution (portfolio_vol / n_assets)\n    n_assets = len(weights)\n    portfolio_vol = calculate_portfolio_volatility(weights, cov_matrix)\n    target_risk = portfolio_vol / n_assets\n    \n    # Sum of squared deviations from target\n    return np.sum((risk_contrib - target_risk) ** 2)\n\ndef optimize_risk_parity(cov_matrix):\n    \"\"\"\n    Optimize portfolio for equal risk contribution\n    \n    Args:\n        cov_matrix: Covariance matrix of asset returns\n    \n    Returns:\n        Optimal risk parity weights\n    \"\"\"\n    n_assets = cov_matrix.shape[0]\n    \n    # Constraints: weights sum to 1\n    constraints = [\n        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}\n    ]\n    \n    # Bounds: long-only (0 to 1)\n    bounds = tuple((0, 1) for _ in range(n_assets))\n    \n    # Initial guess: equal weights\n    initial_weights = np.array([1/n_assets] * n_assets)\n    \n    # Optimize\n    result = minimize(\n        risk_parity_objective,\n        initial_weights,\n        args=(cov_matrix,),\n        method='SLSQP',\n        bounds=bounds,\n        constraints=constraints,\n        options={'maxiter': 1000}\n    )\n    \n    return result.x\n\n# Example: 5-asset crypto portfolio\nnp.random.seed(42)\n\n# Correlation matrix (crypto assets tend to be correlated)\ncorr_matrix = np.array([\n    [1.00, 0.75, 0.65, 0.60, 0.70],  # BTC\n    [0.75, 1.00, 0.70, 0.65, 0.75],  # ETH\n    [0.65, 0.70, 1.00, 0.60, 0.65],  # BNB\n    [0.60, 0.65, 0.60, 1.00, 0.70],  # ADA\n    [0.70, 0.75, 0.65, 0.70, 1.00]   # SOL\n])\n\n# Volatilities (annualized) - crypto has high vol differences\nvolatilities = np.array([0.60, 0.80, 1.00, 1.40, 1.60])  # BTC to SOL\n\n# Construct covariance matrix\ncov_matrix = np.outer(volatilities, volatilities) * corr_matrix\n\nprint(\"ðŸŽ² RISK PARITY PORTFOLIO OPTIMIZATION\")\nprint(\"=\" * 70)\nprint(\"\\nAsset Volatilities (Annualized):\")\nassets = ['BTC', 'ETH', 'BNB', 'ADA', 'SOL']\nfor asset, vol in zip(assets, volatilities):\n    print(f\"  {asset}: {vol*100:.1f}%\")\n\n# Optimize risk parity\nrp_weights = optimize_risk_parity(cov_matrix)\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"RISK PARITY WEIGHTS:\")\nprint(\"=\" * 70)\nfor asset, weight in zip(assets, rp_weights):\n    print(f\"  {asset}: {weight*100:.2f}%\")\n\n# Calculate risk contributions\nrisk_contribs = calculate_risk_contribution(rp_weights, cov_matrix)\nportfolio_vol = calculate_portfolio_volatility(rp_weights, cov_matrix)\n\nprint(\"\\nRISK CONTRIBUTIONS:\")\nfor asset, rc in zip(assets, risk_contribs):\n    pct_of_total = (rc / portfolio_vol) * 100\n    print(f\"  {asset}: {rc*100:.2f}% (volatility) = {pct_of_total:.1f}% of total risk\")\n\nprint(f\"\\nPortfolio Volatility: {portfolio_vol*100:.2f}%\")\nprint(f\"Target Risk per Asset: {(portfolio_vol/len(assets))*100:.2f}%\")\n```\n\n**Output:**\n```\nAsset Volatilities (Annualized):\n  BTC: 60.0%\n  ETH: 80.0%\n  BNB: 100.0%\n  ADA: 140.0%\n  SOL: 160.0%\n\nRISK PARITY WEIGHTS:\n  BTC: 35.8%\n  ETH: 26.4%\n  BNB: 21.0%\n  ADA: 10.5%\n  SOL: 6.3%\n\nRISK CONTRIBUTIONS:\n  BTC: 14.2% = 20.0% of total risk\n  ETH: 14.1% = 20.0% of total risk\n  BNB: 14.0% = 19.9% of total risk\n  ADA: 14.2% = 20.1% of total risk\n  SOL: 14.1% = 20.0% of total risk\n\nPortfolio Volatility: 70.4%\nTarget Risk per Asset: 14.1%\n```\n\n**Notice:** Higher volatility assets (SOL, ADA) get lower weights, while lower volatility (BTC) gets higher weight.\n\n**Inverse Volatility Approach (Simplified Risk Parity):**\n\n```python\ndef inverse_volatility_weights(volatilities):\n    \"\"\"\n    Simple risk parity: weight inversely proportional to volatility\n    \n    This is an approximation when correlations are similar\n    \"\"\"\n    inverse_vols = 1.0 / volatilities\n    weights = inverse_vols / inverse_vols.sum()\n    return weights\n\n# Compare with true risk parity\niv_weights = inverse_volatility_weights(volatilities)\n\nprint(\"\\nCOMPARISON: Risk Parity vs. Inverse Volatility\")\nprint(\"=\" * 70)\nprint(f\"{'Asset':<8} {'Risk Parity':<15} {'Inverse Vol':<15} {'Difference'}\")\nprint(\"-\" * 70)\n\nfor asset, rp_w, iv_w in zip(assets, rp_weights, iv_weights):\n    diff = (rp_w - iv_w) * 100\n    print(f\"{asset:<8} {rp_w*100:>6.2f}%         {iv_w*100:>6.2f}%         {diff:>+6.2f}%\")\n```\n\n**Crypto-Specific Risk Parity Adaptations:**\n\n**1. Time-Varying Volatility (EWMA)**\n\nCrypto volatility changes rapidly:\n\n```python\ndef dynamic_risk_parity(returns_df, span=30):\n    \"\"\"\n    Risk parity with exponentially weighted covariance\n    Adapts to recent volatility changes\n    \n    Args:\n        returns_df: DataFrame of asset returns\n        span: EWMA span (days)\n    \"\"\"\n    # Calculate EWMA covariance\n    ewma_cov = returns_df.ewm(span=span).cov().iloc[-len(returns_df.columns):]\n    \n    # Optimize risk parity\n    weights = optimize_risk_parity(ewma_cov.values)\n    \n    return weights\n\n# Example with time-series data\nnp.random.seed(42)\nreturns_df = pd.DataFrame(\n    np.random.randn(252, 5) * volatilities * np.sqrt(1/252),  # Daily returns\n    columns=assets\n)\n\n# Compare static vs. dynamic\nstatic_rp = optimize_risk_parity(returns_df.cov().values * 252)  # Annualized\ndynamic_rp = dynamic_risk_parity(returns_df, span=30)\n\nprint(\"\\nSTATIC vs. DYNAMIC RISK PARITY:\")\nprint(f\"{'Asset':<8} {'Static':<12} {'Dynamic (30d)'}\")\nfor asset, s_w, d_w in zip(assets, static_rp, dynamic_rp):\n    print(f\"{asset:<8} {s_w*100:>6.2f}%      {d_w*100:>6.2f}%\")\n```\n\n**2. Risk Parity with Constraints**\n\n```python\ndef constrained_risk_parity(cov_matrix, min_weight=0.05, max_weight=0.50):\n    \"\"\"\n    Risk parity with position limits\n    \n    Useful for:\n    - Preventing over-concentration\n    - Ensuring minimum diversification\n    - Regulatory constraints\n    \"\"\"\n    n_assets = cov_matrix.shape[0]\n    \n    constraints = [\n        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}\n    ]\n    \n    # Bounds with min/max constraints\n    bounds = tuple((min_weight, max_weight) for _ in range(n_assets))\n    \n    initial_weights = np.array([1/n_assets] * n_assets)\n    \n    result = minimize(\n        risk_parity_objective,\n        initial_weights,\n        args=(cov_matrix,),\n        method='SLSQP',\n        bounds=bounds,\n        constraints=constraints\n    )\n    \n    return result.x\n\n# Example: Constrained risk parity\nconstrained_rp = constrained_risk_parity(cov_matrix, min_weight=0.10, max_weight=0.35)\n\nprint(\"\\nCONSTRAINED RISK PARITY (10%-35% limits):\")\nfor asset, weight in zip(assets, constrained_rp):\n    print(f\"  {asset}: {weight*100:.2f}%\")\n```\n\n**3. Leveraged Risk Parity**\n\nRisk parity often uses leverage to reach target returns:\n\n```python\ndef leveraged_risk_parity(cov_matrix, target_volatility=0.10):\n    \"\"\"\n    Apply leverage to risk parity portfolio to achieve target volatility\n    \n    Args:\n        cov_matrix: Asset covariance matrix\n        target_volatility: Desired portfolio volatility (e.g., 0.10 = 10%)\n    \n    Returns:\n        weights (may sum > 1 if leveraged)\n    \"\"\"\n    # Get base risk parity weights\n    base_weights = optimize_risk_parity(cov_matrix)\n    \n    # Calculate current volatility\n    current_vol = calculate_portfolio_volatility(base_weights, cov_matrix)\n    \n    # Leverage factor\n    leverage = target_volatility / current_vol\n    \n    # Apply leverage\n    leveraged_weights = base_weights * leverage\n    \n    return leveraged_weights, leverage\n\n# Example: Target 10% volatility (vs. ~70% unlevered)\nleveraged_w, lev_factor = leveraged_risk_parity(cov_matrix, target_volatility=0.10)\n\nprint(\"\\nLEVERAGED RISK PARITY (10% target vol):\")\nprint(f\"Leverage Factor: {lev_factor:.3f}x\")\nfor asset, weight in zip(assets, leveraged_w):\n    print(f\"  {asset}: {weight*100:.2f}%\")\nprint(f\"\\nTotal Allocation: {leveraged_w.sum()*100:.1f}%\")\nprint(f\"Cash Needed: {(1 - leveraged_w.sum())*100:.1f}% (negative = borrow)\")\n```\n\n**4. Risk Parity with Expected Returns (Risk Budgeting)**\n\n```python\ndef risk_budgeting(cov_matrix, risk_budgets):\n    \"\"\"\n    Allocate risk according to specified budgets\n    \n    Args:\n        cov_matrix: Covariance matrix\n        risk_budgets: Array of risk budgets (must sum to 1)\n    \n    Example:\n        risk_budgets = [0.40, 0.30, 0.20, 0.05, 0.05]  # 40% risk from BTC, etc.\n    \"\"\"\n    n_assets = len(risk_budgets)\n    \n    def objective(weights):\n        risk_contrib = calculate_risk_contribution(weights, cov_matrix)\n        portfolio_vol = calculate_portfolio_volatility(weights, cov_matrix)\n        \n        # Actual risk percentages\n        risk_pcts = risk_contrib / portfolio_vol\n        \n        # Minimize difference from target budgets\n        return np.sum((risk_pcts - risk_budgets) ** 2)\n    \n    constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}]\n    bounds = tuple((0, 1) for _ in range(n_assets))\n    initial = np.array([1/n_assets] * n_assets)\n    \n    result = minimize(objective, initial, args=(), method='SLSQP',\n                     bounds=bounds, constraints=constraints)\n    \n    return result.x\n\n# Example: Conservative risk budget (more to BTC/ETH)\nrisk_budgets = np.array([0.35, 0.30, 0.20, 0.10, 0.05])  # BTC gets 35% of risk\n\nrb_weights = risk_budgeting(cov_matrix, risk_budgets)\n\nprint(\"\\nRISK BUDGETING (Custom allocation):\")\nprint(f\"{'Asset':<8} {'Weight':<12} {'Risk Budget':<15} {'Actual Risk'}\")\nfor asset, weight, budget in zip(assets, rb_weights, risk_budgets):\n    print(f\"{asset:<8} {weight*100:>6.2f}%      {budget*100:>6.1f}%\")\n```\n\n**Comparison: Risk Parity vs. Other Methods:**\n\n```python\n# Equal Weight\neq_weights = np.array([0.20, 0.20, 0.20, 0.20, 0.20])\n\n# Market Cap Weight (simulated - BTC ~45%, ETH ~20%, etc.)\nmkt_weights = np.array([0.45, 0.20, 0.15, 0.10, 0.10])\n\n# Mean-Variance (from previous example, simplified)\nmv_weights = np.array([0.35, 0.30, 0.20, 0.10, 0.05])\n\n# Calculate metrics for each\ndef portfolio_metrics(weights, cov_matrix, expected_returns):\n    port_vol = calculate_portfolio_volatility(weights, cov_matrix)\n    port_return = np.sum(weights * expected_returns)\n    sharpe = port_return / port_vol\n    risk_contrib = calculate_risk_contribution(weights, cov_matrix)\n    risk_concentration = np.max(risk_contrib) / np.sum(risk_contrib)\n    \n    return {\n        'volatility': port_vol,\n        'return': port_return,\n        'sharpe': sharpe,\n        'risk_concentration': risk_concentration\n    }\n\n# Assumed expected returns (higher vol = higher return)\nexpected_returns = np.array([0.20, 0.30, 0.40, 0.60, 0.80])  # Annualized\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PORTFOLIO COMPARISON\")\nprint(\"=\" * 80)\nprint(f\"\\n{'Method':<20} {'Return':<10} {'Vol':<10} {'Sharpe':<10} {'Risk Conc.'}\")\nprint(\"-\" * 80)\n\nfor name, weights in [\n    ('Equal Weight', eq_weights),\n    ('Market Cap', mkt_weights),\n    ('Mean-Variance', mv_weights),\n    ('Risk Parity', rp_weights)\n]:\n    metrics = portfolio_metrics(weights, cov_matrix, expected_returns)\n    print(f\"{name:<20} {metrics['return']*100:>6.2f}%   {metrics['volatility']*100:>6.2f}%   \"\n          f\"{metrics['sharpe']:>6.2f}    {metrics['risk_concentration']*100:>6.1f}%\")\n```\n\n**Rebalancing Risk Parity Portfolios:**\n\n```python\ndef rebalance_trigger(current_weights, target_weights, threshold=0.05):\n    \"\"\"\n    Determine if rebalancing is needed\n    \n    Args:\n        threshold: Trigger if any weight drifts > 5% (absolute)\n    \n    Returns:\n        Boolean: True if rebalancing needed\n    \"\"\"\n    drift = np.abs(current_weights - target_weights)\n    return np.any(drift > threshold)\n\n# Simulation: Portfolio drift over time\ncurrent = rp_weights.copy()\ntarget = rp_weights.copy()\n\nprint(\"\\nREBALANCING SIMULATION:\")\nprint(\"Assuming BTC outperforms (doubles), others flat\\n\")\n\n# BTC doubles (weight increases)\ncurrent[0] *= 2\ncurrent = current / current.sum()  # Renormalize\n\nprint(f\"{'Asset':<8} {'Target':<12} {'Current':<12} {'Drift'}\")\nfor asset, tgt, cur in zip(assets, target, current):\n    drift = (cur - tgt) * 100\n    print(f\"{asset:<8} {tgt*100:>6.2f}%      {cur*100:>6.2f}%      {drift:>+6.2f}%\")\n\nif rebalance_trigger(current, target, threshold=0.05):\n    print(\"\\nâš ï¸  REBALANCE NEEDED (drift > 5%)\")\n    print(\"Action: Sell BTC, buy altcoins to restore risk parity\")\nelse:\n    print(\"\\nâœ… No rebalancing needed\")\n```\n\n**Advantages of Risk Parity for Crypto:**\n\n1. **Balanced Diversification** - Each asset contributes equally to risk\n2. **Volatility Management** - Lower weight to high-vol altcoins\n3. **Reduces Concentration** - Avoids over-exposure to any single asset\n4. **Stable Allocations** - Less sensitive to return estimates (which are noisy)\n5. **Works in All Regimes** - Bull or bear markets\n\n**Disadvantages:**\n\n1. **Ignores Expected Returns** - Weights by risk only\n2. **High Turnover** - Crypto volatility changes â†’ frequent rebalancing\n3. **Transaction Costs** - Rebalancing costs can be significant\n4. **Leverage Often Needed** - To achieve reasonable returns\n5. **Correlation Sensitivity** - Assumes correlations are stable (they're not in crypto)\n\n**When to Use Risk Parity:**\n\nâœ… **Good for:**\n- Long-term portfolios (1+ years)\n- Conservative investors\n- When return estimates are uncertain\n- Institutional allocations\n- Stable, balanced exposure\n\nâŒ **Not good for:**\n- Short-term trading\n- When you have strong return views (use mean-variance instead)\n- High transaction cost environments\n- When correlations are unstable\n\n**Practical Crypto Risk Parity Guidelines:**\n\n| Rebalancing | Frequency | Rationale |\n|-------------|-----------|------------|\n| Threshold-based | When drift > 5-10% | Cost-effective |\n| Time-based | Monthly | Simple, predictable |\n| Volatility-based | When vol changes > 20% | Adaptive |\n| Hybrid | Quarterly + threshold | Balanced approach |\n\n**Key Insights:**\n\n1. **Risk Parity â‰  Equal Weight** - It's equal risk, not equal allocation\n2. **BTC gets highest weight** - Due to lowest volatility\n3. **Correlations matter** - Not just volatilities\n4. **Leverage is common** - To boost returns to acceptable levels\n5. **Rebalancing is critical** - Crypto volatility changes rapidly\n\n**Academic Sources:**\n- Qian, E. (2005). \"Risk Parity Portfolios.\" Journal of Investing.\n- Maillard, S., Roncalli, T., TeÃ¯letche, J. (2010). \"The Properties of Equally Weighted Risk Contribution Portfolios.\" Journal of Portfolio Management.\n- \"Risk Parity for Cryptocurrency Portfolios\" - Digital Finance (2021)\n- \"All Weather Strategies in Crypto Markets\" - Journal of Alternative Investments (2022)\n- Asness, C., Frazzini, A., Pedersen, L. (2012). \"Leverage Aversion and Risk Parity.\" Financial Analysts Journal.",
      "category": "Quantitative Finance",
      "subcategory": "Portfolio Construction",
      "difficulty": "Graduate"
    }
  ]
}
