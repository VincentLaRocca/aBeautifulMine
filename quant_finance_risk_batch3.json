{
  "source": "quant_finance_risk_management",
  "created_at": "2025-11-09",
  "total_pairs": 1,
  "description": "Risk Management Q&A - Monte Carlo Simulation for cryptocurrency portfolio risk analysis",
  "qa_pairs": [
    {
      "pair_id": "quant_risk_003",
      "topic": "Monte Carlo Simulation cryptocurrency portfolio risk stochastic modeling scenario analysis",
      "question": "How can Monte Carlo Simulation be applied to cryptocurrency portfolio risk analysis, including generating scenarios, estimating risk metrics, and stress testing portfolios?",
      "answer": "Monte Carlo Simulation is a computational technique that uses repeated random sampling to model the probability distribution of outcomes. For cryptocurrency portfolios, Monte Carlo methods allow us to simulate thousands of potential future price paths, estimate risk metrics (VaR, CVaR, drawdowns), and stress-test strategies under various market conditions. Named after the Monte Carlo Casino due to its use of randomness, this method is essential for understanding crypto's extreme uncertainty and fat-tailed distributions. Here's the comprehensive guide:\n\n**Monte Carlo Simulation Theory:**\n\n**Core Concept:**\n1. Model the stochastic process (e.g., asset price evolution)\n2. Generate random scenarios based on this model\n3. Calculate outcome for each scenario\n4. Aggregate results to estimate probabilities and risk metrics\n\n**Law of Large Numbers:**\nAs simulations increase (N ‚Üí ‚àû), sample mean converges to true expected value.\n\n**For Portfolio Risk:**\n- Simulate 10,000+ future price paths\n- Calculate portfolio value at each path\n- Estimate probability distribution of returns/losses\n- Derive risk metrics (VaR, CVaR, max drawdown, etc.)\n\n**Basic Monte Carlo for Crypto:**\n\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\nprint(\"üé≤ MONTE CARLO SIMULATION FOR CRYPTO PORTFOLIOS\")\nprint(\"=\" * 70)\n\n# Portfolio parameters\nportfolio_value = 100000  # $100k\nweights = np.array([0.40, 0.30, 0.20, 0.10])  # BTC, ETH, BNB, ADA\nassets = ['BTC', 'ETH', 'BNB', 'ADA']\n\n# Historical parameters (annualized)\nexpected_returns = np.array([0.50, 0.80, 1.00, 1.20])  # 50%, 80%, 100%, 120%\nvolatilities = np.array([0.70, 0.90, 1.10, 1.40])  # 70%, 90%, 110%, 140%\n\n# Correlation matrix\ncorrelation = np.array([\n    [1.00, 0.75, 0.60, 0.55],  # BTC\n    [0.75, 1.00, 0.70, 0.65],  # ETH\n    [0.60, 0.70, 1.00, 0.60],  # BNB\n    [0.55, 0.65, 0.60, 1.00]   # ADA\n])\n\n# Covariance matrix\ncovariance = np.outer(volatilities, volatilities) * correlation\n\nprint(\"\\nüìä PORTFOLIO SETUP\")\nprint(\"=\" * 70)\nprint(f\"Initial Value: ${portfolio_value:,}\")\nprint(f\"\\nWeights:\")\nfor asset, w in zip(assets, weights):\n    print(f\"  {asset}: {w*100:.0f}%\")\n\nprint(f\"\\nExpected Returns (annual):\")\nfor asset, r in zip(assets, expected_returns):\n    print(f\"  {asset}: {r*100:.0f}%\")\n\nprint(f\"\\nVolatilities (annual):\")\nfor asset, v in zip(assets, volatilities):\n    print(f\"  {asset}: {v*100:.0f}%\")\n```\n\n**Simulating Future Price Paths:**\n\n```python\ndef monte_carlo_simulation(weights, expected_returns, covariance, \n                           initial_value=100000, n_simulations=10000, \n                           n_days=252, seed=None):\n    \"\"\"\n    Simulate portfolio value paths using Monte Carlo\n    \n    Assumes Geometric Brownian Motion (GBM):\n    dS = Œº √ó S √ó dt + œÉ √ó S √ó dW\n    \n    Args:\n        weights: Portfolio weights\n        expected_returns: Expected returns (annualized)\n        covariance: Covariance matrix (annualized)\n        initial_value: Starting portfolio value\n        n_simulations: Number of simulation paths\n        n_days: Time horizon (trading days)\n        seed: Random seed for reproducibility\n    \n    Returns:\n        Array of portfolio values (n_simulations √ó n_days)\n    \"\"\"\n    if seed is not None:\n        np.random.seed(seed)\n    \n    n_assets = len(weights)\n    dt = 1/252  # Daily timestep\n    \n    # Cholesky decomposition for correlated random variables\n    cholesky = np.linalg.cholesky(covariance)\n    \n    # Storage for all paths\n    portfolio_paths = np.zeros((n_simulations, n_days))\n    portfolio_paths[:, 0] = initial_value\n    \n    for sim in range(n_simulations):\n        # Initialize asset values\n        asset_values = weights * initial_value\n        \n        for day in range(1, n_days):\n            # Generate correlated random shocks\n            random_shocks = np.random.standard_normal(n_assets)\n            correlated_shocks = cholesky @ random_shocks\n            \n            # Update asset values using GBM\n            # S(t+1) = S(t) √ó exp((Œº - œÉ¬≤/2)√ódt + œÉ√ó‚àödt√óŒµ)\n            drift = (expected_returns - 0.5 * np.diag(covariance)) * dt\n            diffusion = np.sqrt(dt) * correlated_shocks\n            \n            asset_values *= np.exp(drift + diffusion)\n            \n            # Portfolio value = sum of asset values\n            portfolio_paths[sim, day] = asset_values.sum()\n    \n    return portfolio_paths\n\n# Run simulation\nprint(\"\\nüé≤ RUNNING SIMULATION\")\nprint(\"=\" * 70)\nprint(f\"Simulations: 10,000\")\nprint(f\"Time horizon: 252 days (1 year)\")\nprint(f\"Model: Geometric Brownian Motion\\n\")\n\npaths = monte_carlo_simulation(\n    weights, expected_returns, covariance,\n    initial_value=portfolio_value,\n    n_simulations=10000,\n    n_days=252,\n    seed=42\n)\n\nprint(f\"Simulation complete!\")\nprint(f\"Output shape: {paths.shape} (simulations √ó days)\")\n```\n\n**Analyzing Simulation Results:**\n\n```python\n# Final portfolio values (end of year)\nfinal_values = paths[:, -1]\n\n# Calculate returns\nfinal_returns = (final_values - portfolio_value) / portfolio_value\n\nprint(\"\\nüìä SIMULATION RESULTS\")\nprint(\"=\" * 70)\nprint(f\"\\nFinal Portfolio Value (1 year):\")\nprint(f\"  Mean:   ${final_values.mean():,.0f}\")\nprint(f\"  Median: ${np.median(final_values):,.0f}\")\nprint(f\"  Std:    ${final_values.std():,.0f}\")\nprint(f\"\\nPercentiles:\")\nfor p in [5, 25, 50, 75, 95]:\n    val = np.percentile(final_values, p)\n    print(f\"  {p}th: ${val:,.0f} ({(val/portfolio_value - 1)*100:+.1f}%)\")\n\nprint(f\"\\nReturns:\")\nprint(f\"  Mean:   {final_returns.mean()*100:+.1f}%\")\nprint(f\"  Median: {np.median(final_returns)*100:+.1f}%\")\nprint(f\"  Std:    {final_returns.std()*100:.1f}%\")\n\n# Probability of loss\nprob_loss = (final_returns < 0).sum() / len(final_returns)\nprint(f\"\\nProbability of Loss: {prob_loss*100:.1f}%\")\nprint(f\"Probability of Gain: {(1-prob_loss)*100:.1f}%\")\n\n# Probability of doubling\nprob_double = (final_returns > 1.0).sum() / len(final_returns)\nprint(f\"Probability of 2x: {prob_double*100:.1f}%\")\n```\n\n**Risk Metrics from Monte Carlo:**\n\n```python\ndef calculate_risk_metrics_mc(paths, confidence_levels=[0.95, 0.99]):\n    \"\"\"\n    Calculate risk metrics from Monte Carlo paths\n    \"\"\"\n    initial_value = paths[0, 0]\n    final_values = paths[:, -1]\n    returns = (final_values - initial_value) / initial_value\n    losses = -returns  # Positive = loss\n    \n    results = {}\n    \n    for conf in confidence_levels:\n        # VaR\n        var = np.percentile(losses, conf * 100)\n        results[f'VaR_{int(conf*100)}'] = var\n        \n        # CVaR (Expected Shortfall)\n        cvar = losses[losses >= var].mean()\n        results[f'CVaR_{int(conf*100)}'] = cvar\n    \n    # Maximum drawdown across all paths\n    max_drawdowns = []\n    for path in paths:\n        running_max = np.maximum.accumulate(path)\n        drawdown = (path - running_max) / running_max\n        max_drawdowns.append(drawdown.min())\n    \n    results['mean_max_drawdown'] = np.mean(max_drawdowns)\n    results['95th_percentile_drawdown'] = np.percentile(max_drawdowns, 95)\n    results['worst_drawdown'] = np.min(max_drawdowns)\n    \n    return results\n\nrisk_metrics = calculate_risk_metrics_mc(paths)\n\nprint(\"\\n‚ö†Ô∏è  RISK METRICS (Monte Carlo)\")\nprint(\"=\" * 70)\nprint(f\"\\n95% VaR:  {risk_metrics['VaR_95']*100:.2f}% (${risk_metrics['VaR_95']*portfolio_value:,.0f} loss)\")\nprint(f\"99% VaR:  {risk_metrics['VaR_99']*100:.2f}% (${risk_metrics['VaR_99']*portfolio_value:,.0f} loss)\")\nprint(f\"\\n95% CVaR: {risk_metrics['CVaR_95']*100:.2f}% (avg loss beyond VaR)\")\nprint(f\"99% CVaR: {risk_metrics['CVaR_99']*100:.2f}%\")\nprint(f\"\\nMax Drawdown:\")\nprint(f\"  Mean:          {risk_metrics['mean_max_drawdown']*100:.1f}%\")\nprint(f\"  95th%ile:      {risk_metrics['95th_percentile_drawdown']*100:.1f}%\")\nprint(f\"  Worst case:    {risk_metrics['worst_drawdown']*100:.1f}%\")\n```\n\n**Stress Testing with Monte Carlo:**\n\n```python\ndef stress_test_scenarios(weights, covariance, initial_value=100000):\n    \"\"\"\n    Stress test portfolio under extreme scenarios\n    \"\"\"\n    scenarios = {\n        'Market Crash 2020': {\n            'returns': np.array([-0.50, -0.60, -0.65, -0.70]),  # March 2020\n            'vol_multiplier': 3.0\n        },\n        'Bull Run 2021': {\n            'returns': np.array([1.50, 2.00, 2.50, 3.00]),\n            'vol_multiplier': 1.5\n        },\n        'Crypto Winter 2022': {\n            'returns': np.array([-0.70, -0.75, -0.80, -0.85]),\n            'vol_multiplier': 2.0\n        },\n        'Flash Crash': {\n            'returns': np.array([-0.30, -0.35, -0.40, -0.45]),  # Single day\n            'vol_multiplier': 5.0\n        }\n    }\n    \n    results = {}\n    \n    for scenario_name, params in scenarios.items():\n        # Adjust parameters\n        stress_returns = params['returns']\n        stress_cov = covariance * (params['vol_multiplier'] ** 2)\n        \n        # Run simulation\n        stress_paths = monte_carlo_simulation(\n            weights, stress_returns, stress_cov,\n            initial_value=initial_value,\n            n_simulations=5000,\n            n_days=30,  # 30-day stress period\n            seed=42\n        )\n        \n        final_vals = stress_paths[:, -1]\n        mean_loss = ((final_vals.mean() - initial_value) / initial_value)\n        worst_loss = ((final_vals.min() - initial_value) / initial_value)\n        \n        results[scenario_name] = {\n            'mean_return': mean_loss,\n            'worst_return': worst_loss,\n            'prob_50pct_loss': (final_vals < initial_value * 0.5).mean()\n        }\n    \n    return results\n\nstress_results = stress_test_scenarios(weights, covariance, portfolio_value)\n\nprint(\"\\nüî• STRESS TEST SCENARIOS\")\nprint(\"=\" * 70)\nfor scenario, metrics in stress_results.items():\n    print(f\"\\n{scenario}:\")\n    print(f\"  Mean return:    {metrics['mean_return']*100:+.1f}%\")\n    print(f\"  Worst return:   {metrics['worst_return']*100:+.1f}%\")\n    print(f\"  Prob 50% loss:  {metrics['prob_50pct_loss']*100:.1f}%\")\n```\n\n**Visualization:**\n\n```python\n# Plot sample paths\nplt.figure(figsize=(14, 10))\n\n# 1. Sample paths\nplt.subplot(2, 2, 1)\nfor i in range(100):\n    plt.plot(paths[i], alpha=0.3, linewidth=0.5)\nplt.plot(paths.mean(axis=0), 'r-', linewidth=2, label='Mean path')\nplt.axhline(portfolio_value, color='black', linestyle='--', label='Initial value')\nplt.title('100 Sample Portfolio Paths')\nplt.xlabel('Days')\nplt.ylabel('Portfolio Value ($)')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\n# 2. Final value distribution\nplt.subplot(2, 2, 2)\nplt.hist(final_values, bins=50, alpha=0.7, edgecolor='black')\nplt.axvline(portfolio_value, color='red', linestyle='--', label='Initial')\nplt.axvline(final_values.mean(), color='green', linestyle='--', label='Mean')\nplt.axvline(np.median(final_values), color='blue', linestyle='--', label='Median')\nplt.title('Distribution of Final Portfolio Values')\nplt.xlabel('Portfolio Value ($)')\nplt.ylabel('Frequency')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\n# 3. Return distribution\nplt.subplot(2, 2, 3)\nplt.hist(final_returns * 100, bins=50, alpha=0.7, edgecolor='black')\nplt.axvline(0, color='red', linestyle='--', label='Break-even')\nplt.axvline(final_returns.mean() * 100, color='green', linestyle='--', label='Mean')\nplt.title('Distribution of Returns (%)')\nplt.xlabel('Return (%)')\nplt.ylabel('Frequency')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\n# 4. Percentile cone\nplt.subplot(2, 2, 4)\npercentiles = [5, 25, 50, 75, 95]\nfor p in percentiles:\n    values = np.percentile(paths, p, axis=0)\n    label = f'{p}th %ile' if p in [5, 50, 95] else None\n    alpha = 0.8 if p == 50 else 0.5\n    plt.plot(values, label=label, alpha=alpha)\nplt.fill_between(range(252), \n                  np.percentile(paths, 5, axis=0),\n                  np.percentile(paths, 95, axis=0),\n                  alpha=0.2, label='5-95%ile range')\nplt.title('Portfolio Value Percentile Cone')\nplt.xlabel('Days')\nplt.ylabel('Portfolio Value ($)')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\n# plt.show()\n\nprint(\"\\nüìà Visualizations created (4 charts)\")\n```\n\n**Advanced Monte Carlo Techniques:**\n\n**1. Jump Diffusion Model**\n\nCrypto has sudden jumps (not just continuous drift):\n\n```python\ndef monte_carlo_jump_diffusion(weights, expected_returns, covariance,\n                                jump_prob=0.05, jump_mean=-0.10, jump_std=0.15,\n                                initial_value=100000, n_simulations=10000, n_days=252):\n    \"\"\"\n    Monte Carlo with jump diffusion (Merton model)\n    \n    Args:\n        jump_prob: Probability of jump per day (e.g., 0.05 = 5% chance)\n        jump_mean: Mean jump size (e.g., -0.10 = -10% on average)\n        jump_std: Jump size standard deviation\n    \"\"\"\n    n_assets = len(weights)\n    dt = 1/252\n    cholesky = np.linalg.cholesky(covariance)\n    \n    portfolio_paths = np.zeros((n_simulations, n_days))\n    portfolio_paths[:, 0] = initial_value\n    \n    for sim in range(n_simulations):\n        asset_values = weights * initial_value\n        \n        for day in range(1, n_days):\n            # Normal diffusion\n            random_shocks = np.random.standard_normal(n_assets)\n            correlated_shocks = cholesky @ random_shocks\n            drift = (expected_returns - 0.5 * np.diag(covariance)) * dt\n            diffusion = np.sqrt(dt) * correlated_shocks\n            \n            # Jump component\n            jump = np.zeros(n_assets)\n            if np.random.random() < jump_prob:\n                jump = np.random.normal(jump_mean, jump_std, n_assets)\n            \n            # Update with jumps\n            asset_values *= np.exp(drift + diffusion + jump)\n            portfolio_paths[sim, day] = asset_values.sum()\n    \n    return portfolio_paths\n\nprint(\"\\n‚ö° JUMP DIFFUSION MODEL\")\nprint(\"=\" * 70)\nprint(\"Adds sudden jumps to continuous diffusion\")\nprint(\"Better captures crypto flash crashes\")\nprint(\"Example: 5% daily jump probability, avg -10% jump\")\n```\n\n**2. GARCH-based Monte Carlo**\n\nTime-varying volatility:\n\n```python\nfrom arch import arch_model\n\ndef monte_carlo_garch(returns, n_simulations=1000, n_days=252):\n    \"\"\"\n    Monte Carlo with GARCH volatility forecasts\n    \"\"\"\n    # Fit GARCH(1,1)\n    model = arch_model(returns * 100, vol='Garch', p=1, q=1)\n    fitted = model.fit(disp='off')\n    \n    # Forecast\n    forecasts = fitted.forecast(horizon=n_days, simulations=n_simulations)\n    \n    # Extract simulated returns\n    simulated_returns = forecasts.simulations.values[0] / 100  # Rescale\n    \n    # Convert to price paths\n    initial_price = 1.0\n    price_paths = initial_price * np.exp(np.cumsum(simulated_returns, axis=1))\n    \n    return price_paths\n\nprint(\"\\nüìä GARCH MONTE CARLO\")\nprint(\"Uses GARCH for time-varying volatility\")\nprint(\"More realistic for crypto (volatility clusters)\")\n```\n\n**3. Copula-based Monte Carlo**\n\nBetter capture tail dependencies:\n\n```python\nfrom scipy.stats import norm, t\n\ndef monte_carlo_copula(marginals, copula_type='gaussian', \n                       n_simulations=10000, correlation=None):\n    \"\"\"\n    Monte Carlo using copulas for dependency structure\n    \n    Args:\n        marginals: List of scipy.stats distributions for each asset\n        copula_type: 'gaussian' or 't' (t-copula better for crypto)\n        correlation: Correlation matrix\n    \"\"\"\n    n_assets = len(marginals)\n    \n    if copula_type == 'gaussian':\n        # Generate correlated uniform samples\n        z = np.random.multivariate_normal(np.zeros(n_assets), correlation, n_simulations)\n        u = norm.cdf(z)  # Convert to uniform [0,1]\n    \n    elif copula_type == 't':\n        # t-copula (better tail dependence)\n        df = 5  # Degrees of freedom\n        z = np.random.multivariate_normal(np.zeros(n_assets), correlation, n_simulations)\n        chi2 = np.random.chisquare(df, n_simulations)[:, np.newaxis]\n        t_samples = z / np.sqrt(chi2 / df)\n        u = t.cdf(t_samples, df)\n    \n    # Transform to marginal distributions\n    samples = np.zeros((n_simulations, n_assets))\n    for i, marginal in enumerate(marginals):\n        samples[:, i] = marginal.ppf(u[:, i])\n    \n    return samples\n\nprint(\"\\nüîó COPULA-BASED MONTE CARLO\")\nprint(\"Separates marginal distributions from dependence\")\nprint(\"t-copula better captures extreme co-movements\")\n```\n\n**Crypto-Specific Monte Carlo Best Practices:**\n\n```python\nprint(\"\\n‚úÖ MONTE CARLO BEST PRACTICES FOR CRYPTO\")\nprint(\"=\" * 70)\nprint(\"\"\"\n1. Model Selection:\n   - Geometric Brownian Motion: Baseline (simple)\n   - Jump Diffusion: Better for crypto (flash crashes)\n   - GARCH: Best for volatility clustering\n   - t-copula: Best for tail dependencies\n\n2. Calibration:\n   - Use recent data (3-12 months for crypto)\n   - Estimate on returns, not prices\n   - Fat-tailed distributions (Student's t, not Normal)\n   - Higher correlation in crashes (use copulas)\n\n3. Simulation Parameters:\n   - Simulations: 10,000+ for VaR, 100,000+ for CVaR\n   - Time horizon: Realistic (1-30 days for crypto)\n   - Daily timestep (hourly for intraday)\n   - Check convergence (results stable as N increases)\n\n4. Validation:\n   - Backtest: Do simulated distributions match reality?\n   - Calibration test: VaR violations ‚âà expected?\n   - Stress test: Extreme scenarios included?\n   - Sensitivity: Results robust to parameter changes?\n\n5. Risk Metrics:\n   - VaR: Good for regulatory compliance\n   - CVaR: Better for portfolio optimization\n   - Max Drawdown: Critical for crypto (can be 80%+)\n   - Time to recovery: How long to recover from drawdown?\n\n6. Common Pitfalls:\n   ‚ùå Using normal distribution (crypto is fat-tailed!)\n   ‚ùå Too few simulations (< 1,000)\n   ‚ùå Ignoring jumps/crashes\n   ‚ùå Static correlation (changes in stress)\n   ‚ùå No validation against reality\n   ‚úÖ Fat tails, 10k+ sims, jumps, stress tests, validate!\n\"\"\")\n```\n\n**Key Insights:**\n\n1. **Monte Carlo is flexible** - Can model any stochastic process\n2. **Garbage in, garbage out** - Calibration is critical\n3. **More simulations = better** - But diminishing returns after 10k\n4. **Normal distribution fails for crypto** - Use fat tails!\n5. **Validate, validate, validate** - Simulations must match reality\n\n**Academic Sources:**\n- Metropolis, N., Ulam, S. (1949). \"The Monte Carlo Method.\" Journal of the American Statistical Association.\n- Glasserman, P. (2003). \"Monte Carlo Methods in Financial Engineering.\" Springer.\n- \"Monte Carlo Simulation for Cryptocurrency Risk\" - Journal of Risk (2021)\n- Merton, R.C. (1976). \"Option Pricing When Underlying Stock Returns Are Discontinuous.\" Journal of Financial Economics.\n- \"Copula-Based Monte Carlo for Crypto Portfolios\" - Quantitative Finance (2022).",
      "category": "Quantitative Finance",
      "subcategory": "Risk Management",
      "difficulty": "Graduate"
    }
  ]
}
